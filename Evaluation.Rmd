---
title: "Evaluation"
output:
  html_document:
    number_sections: yes
    theme: sandstone
    toc: yes
    toc_depth: 3
    toc_float: yes
---

```{r, include=FALSE}
knitr::opts_chunk$set(tidy=TRUE, fig.align='center')
```

```{r, echo=FALSE, include=FALSE}
library(rlang)
library(pryr)
library(knitr)
library(kableExtra)
library(magrittr)
library(dplyr)
library(tidyverse)
library(lobstr)
library(memoise)
library(purrr)
```

# Evaluation
## Introduction
The user-facing opposite of quotation is unquotation: it gives the user the ability to selectively evaluate parts of an otherwise quoted argument. The developer-facing complement of quotation is evaluation: this gives the developer the ability to evaluate quoted expressions in custom environments to achieve specific goals.

This chapter begins with a discussion of evaluation in its purest form with `rlang::eval_bare()` which evaluates an expression in given environment. We’ll then see how these ideas are used to implement a handful of base R functions, and then learn about the similar `base::eval()`.

The meat of the chapter focusses on extensions needed to implement evaluation robustly. There are two big new ideas:

* We need a new data structure that captures both the expression and the environment associated with each function argument. We call this data structure a quosure.

* `base::eval()` supports evaluating an expression in the context of a data frame and an environment. We formalise this idea by calling it data mask and to resolve the ambiguity it creates, introduce the idea of data pronouns.

Together, quasiquotation, quosures, data masks, and pronouns form what we call tidy evaluation, or tidy eval for short. Tidy eval provides a principled approach to NSE that makes it possible to use such functions both interactively and embedded with other functions. We’ll finish off the chapter showing the basic pattern you use to wrap quasiquoting functions, and how you can adapt that pattern to base R NSE functions.

## Evaluation basics
In the previous chapter, we briefly mentioned eval(). Here, however, we’re going to start with `rlang::eval_bare()` which is the purest evocation of the idea of evaluation. The first argument, `expr` is an expression to evaluate. This will usually be either a symbol or expression:

```{r}
x <- 10
eval_bare(expr(x))

y <- 2
eval_bare(expr(x + y))
```

Everything else yields itself when evaluated:

```{r}
eval_bare(10)
```

The second argument, `env`, gives the environment in which the expression should be evaluated, i.e. where should the values of `x`, `y`, and `+` be looked for? By default, this is the current environment, i.e. the calling environment of `eval_bare()`, but you can override it if you want:

```{r}
eval_bare(expr(x + y), env(x = 1000))
```

Because R looks up functions in the same way as variables, we can also override the meaning of functions. This is a very useful technique if you want to translate R code into something else, as you’ll learn about in the next chapter.

```{r}
eval_bare(
  expr(x + y), 
  env(`+` = function(x, y) paste0(x, " + ", y))
  )
```

Note that the first argument to `eval_bare()` (and to `base::eval()`) is evaluated, not quoted. This can lead to confusing results if you forget to quote the input:

```{r}
eval_bare(x + y)
eval_bare(x + y, env(x = 1000))
```

### Application: `local()`
Sometimes you want to perform a chunk of calculation that creates a bunch of intermediate variables. The intermediate variables have no long-term use and could be quite large, so you’d rather not keep them around. One approach is to clean up after yourself using `rm()`; another approach is to wrap the code in a function, and just call it once. A more elegant approach is to use `local()`:

```{r, error=TRUE}
# Clean up variables created earlier
rm(x, y)

foo <- local({
  x <- 10
  y <- 200
  x + y
})

foo
x
y
```

The essence of `local()` is quite simple. We capture the input expression, and create a new environment in which to evaluate it. This inherits from the caller environment so it can access the current lexical scope, but any intermediate variables will be GC’d once the function has returned.

```{r, error=TRUE}
local2 <- function(expr) {
  env <- child_env(caller_env())
  eval_bare(enexpr(expr), env)
}

foo <- local2({
  x <- 10
  y <- 200
  x + y
})

foo
x
y
```

### Application: `source()`
We can create a simple version of `source()` by combining `parse_expr()` and `eval_bare()`. We read in the file from disk, use `parse_expr()` to parse the string into a list of expressions, and then use `eval_bare()` to evaluate each component in turn. This version evaluates the code in the caller environment, and invisibly returns the result of the last expression in the file like `source()`.

```{r}
source2 <- function(path, env = caller_env()) {
  file <- paste(readLines(path, warn = FALSE), collapse = "\n")
  exprs <- parse_exprs(file)

  res <- NULL
  for (i in seq_along(exprs)) {
    res <- eval_bare(exprs[[i]], env)
  }
  
  invisible(res)
}
```

The real `source()` is considerably more complicated because it can echo input and output, and has many other settings that control its behaviour.

### Base R
The base function equivalent to `eval_bare()` is the two-argument form of `eval()`: `eval(expr, envir)`:

```{r}
eval(expr(x + y), env(x = 1000, y = 1))
```

The final argument, `enclos` provides support for data masks, which you’ll learn about in tidy evaluation.

`eval()` is paired with two helper functions:

* `evalq(x, env)` quotes its first argument, and is hence a shortcut for `eval(quote(x), env)`.

* `eval.parent(expr, n)` is shortcut for `eval(expr, env = parent.frame(n))`.

### Exercises
1. Carefully read the documentation for `source()`. What environment does it use by default? What if you supply `local = TRUE`? How do you provide a custom argument?  
**A**: By default, `local = FALSE` hence the global environment is used. If `local = TRUE` then the calling environment is used. If `local` is an environment, then that is used.
    ```{r, eval=FALSE}
    # code snippet from source()
    
    envir <- if (isTRUE(local)) 
        parent.frame()
    else if (isFALSE(local)) 
        .GlobalEnv
    else if (is.environment(local)) 
        local
    else stop("'local' must be TRUE, FALSE or an environment")
    ```
For example:
```{r}
tmp <- tempfile()
writeLines("print(x)", tmp)  # create a temporary R-script

x <- 2

source_local <- function(file, local){
  local({
    x <- 3
    source(file, local = local)
  })      
}

env2 <- rlang::env(x = 4)

source_local(tmp, FALSE)
source_local(tmp, TRUE)
source_local(tmp, env2)
```

2. Predict the results of the following lines of code:
    ```{r}
    eval(quote(eval(quote(eval(quote(2 + 2))))))
    eval(eval(quote(eval(quote(eval(quote(2 + 2)))))))
    quote(eval(quote(eval(quote(eval(quote(2 + 2)))))))
    ```
**A**: `4`, `4`, `eval(quote(eval(quote(eval(quote(2 + 2))))))`

3. Write an equivalent to `get()` using `sym()` and `eval_bare()`. Write an equivalent to `assign()` using `sym()`, `expr()`, and `eval_bare()`. (Don’t worry about the multiple ways of choosing an environment that `get()` and `assign()` support; assume that the user supplies it explicitly.)
    ```{r, eval=FALSE}
    # name is a string
    get2 <- function(name, env) {}
    assign2 <- function(name, value, env) {}
    ```
**A**:
    ```{r, error=TRUE}
    get2 <- function(name, env = caller_env()) {
      eval_bare(sym(name), env)
    }
    
    rm(x, y)
    x <- 10
    get2("x")
    get2("y")
    
    
    assign2 <- function(name, value, env = caller_env()) {
      eval_bare(expr(!!sym(name) <- !!value), env) # evaluates expression of type x <- 10
      # eval_bare(expr(!!name <- !!value), env) # this also works since "x" <- `0 is syntactically ok
    }

    rm(x)
    assign2("x", 10)
    x
    ```

4. Modify `source2()` so it returns the result of every expression, not just the last one. Can you eliminate the for loop?  
**A**:
    ```{r}
    source2 <- function(path, env = caller_env()) {
      file <- paste(readLines(path, warn = FALSE), collapse = "\n")
      exprs <- parse_exprs(file)
      map(exprs, eval_bare, env)
    }
    
    tmp <- tempfile()
    writeLines("x<-2\nx <- x^2\ny<-3", tmp)  # create a temporary R-script
    readLines(tmp)
    
    source2(tmp)
    ```

5. The code generated by `source2()` lacks source references. Read the source code for `sys.source()` and the help for `srcfilecopy()`, then modify `source2()` to preserve source references. You can test your code by sourcing a function that contains a comment. If successful, when you look at the function, you’ll see the comment and not just the source code.  
**A**: not sure what this question is asking. `parse_expr()` appears to already create a srcref.
    ```{r}
    source2 <- function(path, env = caller_env()) {
      file <- paste(readLines(path, warn = FALSE), collapse = "\n")
      exprs <- parse_exprs(file)
      map(exprs, eval_bare, env)
    }
    
    tmp <- tempfile()
    writeLines("function(x) { \n # this a function \n x ^ 2 }", tmp)  # create a temporary R-script
    readLines(tmp)
    
    res <- source2(tmp)
    res # prints function without comment
    res[[1]] # prints function with comment!
    
    res[[1]](5) # returns 25
    str(res[[1]]) # function has srcref attribute
    attributes(res[[1]])[[1]] # source code stored by srcref attribute - prints out same as res[[1]]!
    ```

6. We can make `base::local()` slightly easier to understand by spreading out over multiple lines:
    ```{r, eval=FALSE}
    local3 <- function(expr, envir = new.env()) {
      call <- substitute(eval(quote(expr), envir))
      eval(call, envir = parent.frame())
    }
    ```

Explain how `local()` works in words. (Hint: you might want to `print(call`) to help understand what `substitute()` is doing, and read the documentation to remind yourself what environment `new.env()` will inherit from.)
**A**:
```{r, error=TRUE}
local3 <- function(expr, envir = new.env()) {
  call <- substitute(eval(quote(expr), envir))
  print(call)
  eval(call, envir = parent.frame())
}

rm(x, y)
Z < 50
foo <- local3({
  x <- 10
  y <- 200
  x + y + z
})

# the print of call gives
# eval(quote({
#     x <- 10
#     y <- 200
#     x + y + z
# }), new.env())
```
**A**: the variable `call` is an expression of the form `eval(quote(expr), envir)`, but where `expr` and `envir` have now been substituted for the aruments passed to `local3`. which is evaluated in the calling environment (`parent.frame()`).  The evaluation of call

## Quosures
The simplest form of evaluation combines an expression and an environment. This coupling is so important that we need a data structure that can hold both pieces: we need a quosure, a portmanteau of quoting and closure. 

### Motivation
Quosures are important when the distance between capturing and evaluating an expression grows. Take this simple, if somewhat contrived example:

```{r}
foo <- function(x) {
  y <- 100
  x <- enexpr(x)
  
  eval_bare(x)
}
```

It appears to work for simple cases:

```{r}
z <- 100
foo(z * 2)
```

But if our expression uses `y` it will find the wrong one:

```{r}
y <- 10
foo(y * 2)
```

We could fix this by manually specifying the correct environment:

```{r}
foo2 <- function(x) {
  y <- 100
  x <- enexpr(x)
  
  eval_bare(x, caller_env())
}

y <- 10
foo2(y * 2)
```

That works for this simple case, but does not generalise well. Take this more complicated example that uses `...`. Each argument to `f()` needs to be evaluated in a different environment:

```{r}
f <- function(...) {
  x <- 1
  g(..., x = x)
}

g <- function(...) {
  x <- 2
  h(..., x = x)
}

h <- function(...) {
  exprs <- enexprs(...)
  purrr::map_dbl(exprs, eval_bare, env = caller_env())
}

x <- 0
f(x = x)
```

We can overcome this problem by using two new tools that you’ll learn about shortly: we capture with `enquos()` instead of `enexprs()`, and evaluate with `eval_tidy()` instead of `eval_bare()`:

```{r}
h <- function(...) {
  exprs <- enquos(...)
  purrr::map_dbl(exprs, eval_tidy)
}

x <- 0
f(x = x)
```

This ensures that each expression is evaluated in the correct environment.

### Creating and manipulating
Each of the `expr()` functions that you learned about in the previous chapter has an equivalent `quo()` function that creates a quosure:

Use `quo()` and `quos()` to capture your expressions.

```{r}
quo(x + y + z)
quos(x + 1, y + 2)
```

Use `enquo()` and `enquos()` to capture user-supplied expressions.

```{r}
foo <- function(x) enquo(x)
foo(a + b)
```

Finally, you can use `new_quosure()` to create a quosure from its components: an expression and an environment.

```{r}
x <- new_quosure(expr(x + y), env(x = 1, y = 10))
x
```

If you need to turn a quosure into text for output to the console you can use `quo_name()`, `quo_label()`, or `quo_text()`. `quo_name()` and `quo_label()` are guaranteed to be short; `quo_expr()` may span multiple lines.

```{r}
y <- quo(long_function_name(
  argument_1 = long_argument_value,
  argument_2 = long_argument_value,
  argument_3 = long_argument_value,
  argument_4 = long_argument_value
))
quo_name(y)   # e.g. for data frames
quo_label(y)  # e.g. for error messages
quo_text(y)   # for longer messages
```

### Evaluating
You can evaluate a quosure with `eval_tidy()`:

```{r}
x <- new_quosure(expr(x + y), env(x = 1, y = 10))
eval_tidy(x)
```

And you can extract its components with the quo_get_ helpers:

```{r}
quo_get_env(x)
quo_get_expr(x)
```

For this simple case, `eval_tidy()` is basically a wrapper around `eval_bare()`. In the next section, you’ll learn about the data argument which makes `eval_tidy()` particularly powerful.

```{r}
eval_bare(quo_get_expr(x), quo_get_env(x))
```

### Implementation
Quosures rely on R’s internal representation of function arguments as a special type of object called a promise. A promise captures the expression needed to compute the value and the environment in which to compute it. You’re not normally aware of promises because the first time you access a promise its code is evaluated in its environment, yielding a value. This is what powers lazy evaluation. You cannot manipulate promises with R code. Promises are like a quantum state: any attempt to inspect them with R code will force an immediate evaluation, making the promise disappear. To work around this, rlang manipulates promises with C code, reifying them into an R object that you can work with.

There is one big difference between promises and quosures. A promise is evaluated once, when you access it for the first time. Every time you access it subsequently it will return the same value. A quosure must be evaluated explicitly, and each evaluation is independent of the previous evaluations.

```{r}
# The argument x is evaluated once, then reused
foo <- function(x_arg) {
  list(x_arg, x_arg)
}
foo(runif(3))

# The quosure x is evaluated afresh each time
x_quo <- quo(runif(3))
eval_tidy(x_quo)
eval_tidy(x_quo)
```

### When not to use quosures
Almost all quoting functions should capture quosures rather than expressions, and you should default to using `enquo()` and `enquos()` to capture arguments from the user. You should only use expressions if you have explicitly decided that the environment is not important. This tends to happen in three main cases:

* In code generation, such as you saw in Slicing an array.
* When you are wrapping a NSE function that doesn’t use quosures. We’ll disucss this in detail in the case study at the end of the chapter.
* When you have carefully created a self-contained expression using unquoting. For example, instead of this quosure:

```{r}
base <- 2
quo(log(x, base = base))
```

You could create this self-contained expression:

```{r}
expr(log(x, base = !!base))
```

(Assuming that x will be supplied in some other way)

### Exercises
1. Predict what evaluating each of the following quosures will return.
    ```{r}
    q1 <- new_quosure(expr(x), env(x = 1))
    q1
    
    q2 <- new_quosure(expr(x + !!q1), env(x = 10))
    q2
    
    q3 <- new_quosure(expr(x + !!q2), env(x = 100))
    q3
    ```
**A**: 1, 11, 111
    ```{r}
    q1 <- new_quosure(expr(x), env(x = 1))
    eval_tidy(q1)
    
    q2 <- new_quosure(expr(x + !!q1), env(x = 10))
    eval_tidy(q2)
    
    q3 <- new_quosure(expr(x + !!q2), env(x = 100))
    eval_tidy(q3)
    ```

2. Write a function `enenv()` that captures the environment associated with an argument.  
**A**:
    ```{r}
    enenv <- function(x) {
      expr <- enquo(x)
      quo_get_env(expr)
    }
    
    x <- 10
    enenv(x)
    
    g <- function() {
      x <- 10
      enenv(x)
    }
    g()
    env_parent(g())
    ```

## Tidy evaluation
In the previous section, you learned how to capture quosures, why they are important, and the basics of `eval_tidy()`. In this section, we’ll go deep on `eval_tidy()` and talk more generally about the ideas of tidy evaluation. There are two big new concepts:

* A data mask is a data frame where the evaluated code will look first for variable definitions.
* A data mask introduces ambiguity, so to remove that ambiguity when necessary we introduce pronouns.

We’ll explore tidy evaluation in the context of `base::subset()`, because it’s a simple yet powerful function that encapsulates one of the central ideas that makes R so elegant for data analysis. Once we’ve seen the tidy implementation, we’ll return to the base R implementation, learn how it works, and explore the limitations that make `subset()` suitable only for interactive usage.

### Data masks
In the previous section, you learned that `eval_tidy()` is basically a wrapper around `eval_bare()` when evaluating a quosure. The real power of `eval_tidy()` comes with the second argument: data. This lets you set up a data mask, where variables in the environment are potentially masked by variables in a data frame. This allows you to mingle variables from the environment and variables from a data frame:

```{r}
x <- 10
df <- data.frame(y = 1:10)
q1 <- quo(x * y)

eval_tidy(q1, df)
```

The data mask is the key idea that powers base functions like `with()`, `subset()` and `transform()`, and that is used throughout tidyverse, in packages like dplyr.

How does this work? Unlike environments, data frames don’t have parents, so we can effectively turn it into an environment using the environment of the quosure as its parent. The above code is basically equivalent to:

```{r}
df_env <- as_environment(df, parent = quo_get_env(q1))
q2 <- quo_set_env(q1, df_env)

eval_tidy(q2)
```

### Application: `subset()`:
To see why the data mask is so useful, lets implement our own version of `subset()`. If you haven’t used it before, `subset()` (like `dplyr::filter()`), provides a convenient way of selecting rows of a data frame using an expression that is evaluated in the context of the data frame. It allows you to subset without repeatedly referring to the name of the data frame:

```{r}
sample_df <- data.frame(a = 1:5, b = 5:1, c = c(5, 3, 1, 4, 1))

# Shorthand for sample_df[sample_df$a >= 4, ]
subset(sample_df, a >= 4)

# Shorthand for sample_df[sample_df$b == sample_df$c, ]
subset(sample_df, b == c)
```

The core of our version of `subset()`, `subset2()`, is quite simple. It takes two arguments: a data frame, `df`, and an expression, `rows`. We evaluate `rows` using `df` as a data mask, then use the results to subset the data frame with `[`. I’ve included a very simple check to ensure the result is a logical vector; real code should do more work to create an informative error.

```{r}
subset2 <- function(df, rows) {
  rows <- enquo(rows)
  
  rows_val <- eval_tidy(rows, df)
  stopifnot(is.logical(rows_val))
  
  df[rows_val, , drop = FALSE]
}

subset2(sample_df, b == c)
```

### Application: `arrange()`
A slightly more complicated exercise is to implement the heart of `dplyr::arrange()`. The goal of `arrange()` is to allow you to sort a data frame by multiple variables, each evaluated in the context of the data frame. This is more challenging than `subset()` because we want to arrange by multiple variables captured in `...`.

```{r}
arrange2 <- function(.df, ..., .na.last = TRUE) {
  # Capture all dots
  args <- enquos(...)
  
  # Create a call to order, using `!!!` to splice in the 
  # individual expressions, and `!!` to splice in na.last
  order_call <- quo(order(!!!args, na.last = !!.na.last))
  
  # Evaluate the call to order with 
  ord <- eval_tidy(order_call, .df)
  
  .df[ord, , drop = FALSE]
}

df <- data.frame(x = c(2, 3, 1), y = runif(3))

arrange2(df, x)
arrange2(df, -y)
```

### Ambiguity and pronouns
One of the downsides of the data mask is that it introduces ambiguity: when you say `x`, are you refering to a variable in the data or in the environment? This ambiguity is ok when doing interactive data analysis because you are familiar with the data, and if there are problems, you’ll spot them quickly because you are looking at the data frequently. However, ambiguity becomes a problem when you start programming with functions that use tidy evaluation. For example, take this simple wrapper:

```{r}
threshold_x <- function(df, val) {
  subset2(df, x >= val)
}
```

This function can silently return an incorrect result in two situations:

* If `df` does not contain a variable called `x` and `x` exists in the calling environment, `threshold_x()` will silently return an incorrect result:

```{r}
x <- 10
no_x <- data.frame(y = 1:3)
threshold_x(no_x, 2)
threshold_x(no_x, 20)

# works as intended if x is a column
yes_x <- data.frame(x = 1:3)
threshold_x(yes_x, 2)
```

* If `df` contains a variable called `val`, the function will always return an incorrect answer:

```{r}
has_val <- data.frame(x = 1:3, val = 9:11)
threshold_x(has_val, 2)

has_val <- data.frame(x = 4:6, val = c(5, 5, 5))
threshold_x(has_val, 2)
```

These failure modes arise because tidy evaluation is ambiguous: each variable can be found in either the data mask or the environment. To make this function work we need to remove that ambiguity and ensure that `x` is always found in the data and `val` in the environment. To make this possible `eval_tidy()` provides `.data` and `.env` pronouns:

```{r, error=TRUE}
threshold_x <- function(df, val) {
  subset2(df, .data$x >= .env$val)
}

x <- 10
threshold_x(no_x, 2)

has_val <- data.frame(x = 1:3, val = 9:11)
threshold_x(has_val, 2)
```

Generally, whenever you use the `.env` pronoun, you can use unquoting instead:

```{r}
threshold_x <- function(df, val) {
  subset2(df, .data$x >= !!val)
}
```

There are subtle differences in when `val` is evaluated. If you unquote, `val` will be evaluated by `enquo()`; if you use a pronoun, `val` will be evaluated by `eval_tidy()`. These differences are usually unimportant, so pick the form that looks most natural.

What if we generalise `threshold_x()` slightly so that the user can pick the variable used for thresholding. There are two basic approaches. Both start by capturing a *symbol*:

```{r}
threshold_var1 <- function(df, var, val) {
  var <- ensym(var)
  subset2(df, `$`(.data, !!var) >= !!val)
}

threshold_var2 <- function(df, var, val) {
  var <- as.character(ensym(var))
  subset2(df, .data[[var]] >= !!val)
}

df <- data.frame(x = 1:3, val = 9:11)
threshold_var1(df, x, 2)
threshold_var2(df, val, 11)
```

In `threshold_var1` we need to use the prefix form of `$`, because `.data$!!var` is not valid R syntax. Alternatively, we can convert the symbol to a string, and use `[[`.

### Base `subset()`:
Why is `subset()` dangerous for programming and how does tidy evaluation help us avoid those dangers? First, lets implement the key parts of `subset()` using base R, following the same structure as `subset2()`. We convert `enquo()` to `substitute()` and `eval_tidy()` to `eval()`. We also need to supply a backup environment to `eval()`. There’s no way to access the environment associated with an argument in base R, so we take the best approximation: the caller environment (aka parent frame).

```{r}
subset_base <- function(data, rows) {
  rows <- substitute(rows)
  
  rows_val <- eval(rows, data, caller_env())
  stopifnot(is.logical(rows_val))
  
  data[rows_val, , drop = FALSE]
}
```

There are three problems with this implementation:

* `subset()` doesn’t support unquoting, so wrapping the function is hard. First, you use `substitute()` to capture the complete expression, then you evaluate it. Because `substitute()` doesn’t use a syntactic marker for unquoting, it is hard to see exactly what’s happening here.

```{r}
f1a <- function(df, expr) {
  call <- substitute(subset(df, expr))
  eval(call, caller_env())
}

df <- data.frame(x = 1:3, y = 3:1)
f1a(df, x == 1)
```

I think the tidy evaluation equivalent is easier to understand because the quoting and unquoting is explicit:

```{r}
f1b <- function(df, expr) {
  expr <- enquo(expr)
  subset2(df, !!expr)
}

f1b(df, x == 1)
```

* `base::subset()` always evaluates rows in the parent frame, but if `...` has been used, then the expression might need to be evaluated elsewhere:

```{r}
f <- function(df, ...) {
  xval <- 3
  subset(df, ...)
}

xval <- 1
f(df, x == xval)
```

Because `enquo()` captures the environment of the argument as well as its expression, this is not a problem with `subset2()`:

```{r}
f <- function(df, ...) {
  xval <- 10
  subset2(df, ...)
}

xval <- 1
f(df, x == xval)
```

* Finally, `eval()` doesn’t provide any pronouns so there’s no way to write a safe version of `threshold_x()`.

## Performance
Note that there is some performance overhead when evaluating a quosure compared to evaluating an expression.

However, most of the overhead is due to setting up the data mask so if you need to evaluate code repeatedly, it’s a good idea to define the data mask once then reuse it. This considerably reduces the overhead, with a small change in behaviour: if the code being evaluated creates objects in the “current” environment, those objects will persist across calls.

```{r}
mask <- as_data_mask(mtcars)
eval_tidy(quo(cyl * 2), mask)

eval_tidy(quo(new <- cyl + am), mask)
eval_tidy(quo(new * 2), mask)
```

### Exercises


